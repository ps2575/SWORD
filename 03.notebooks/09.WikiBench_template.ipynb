{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3f107-6869-4c95-ab84-710942738634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import datasets\n",
    "import multiprocessing\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9502e-0b28-4b87-9d33-eb77e2a598b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b365d-6984-4c0a-bfa3-96d33b4fefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_DIR = '../00.data/01.model_response/00.gemini_response/'\n",
    "RESPONSE_NAME = ['00.original_response_500.parquet',\n",
    "                 '01.subject_shuffled_response_500.parquet',\n",
    "                 '02.object_shuffled_response_500.parquet',\n",
    "                 '03.property_scoped_subject_shuffled_response_500.parquet',\n",
    "                 '04.property_scoped_object_shuffled_response_500.parquet']\n",
    "\n",
    "LANGUAGE_LIST = ['en', 'fr', 'de', 'es', 'it', 'pt', 'ko', 'ja']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b4da4-cf48-4909-9913-8a6709cd8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATES = [pq.read_table(f\"{RESPONSE_DIR}{name}\").to_pandas() for name in RESPONSE_NAME]\n",
    "TEMPLATES_COPY = [template.copy() for template in TEMPLATES]\n",
    "BENCHMARKS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3ff4a-5f54-4f28-89f6-ea51467ee646",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_ANSWER = re.compile(r\"<answer>(.*?)</answer>\", re.DOTALL | re.IGNORECASE)\n",
    "def extract_answer(response):\n",
    "    sentence = EXTRACT_ANSWER.search(response)\n",
    "    return sentence.group(1).strip()\n",
    "\n",
    "def make_benchmark_prompt(sentence):\n",
    "    prompt = (\n",
    "        f\"Is the following statement True or False? \"\n",
    "        f\"statement: {sentence} \"\n",
    "        f\"Answer must be one of the following options: \"\n",
    "        f\"True, False, Unsure. \"\n",
    "        f\"Answer must be encapsulated with <answer></answer> \"#, for example <answer>True</answer> \"\n",
    "        f\"Output: <answer>\"\n",
    "    )\n",
    "        \n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d22598-fa1c-428a-a3fb-b6062a4d1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATES_COPY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33ab5c-9355-427c-a209-da5f00a8248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in TEMPLATES_COPY:\n",
    "    df.insert(0, 'row_id', df.index)\n",
    "    drop_cols = [col for col in df.columns if col.startswith(\"TF_\")]\n",
    "    df = df.drop(columns = drop_cols, errors = 'ignore')\n",
    "                 \n",
    "    for lang in LANGUAGE_LIST:\n",
    "        # gemini 생성 문장에서 <answer> 태그 기준 추출한 문장\n",
    "        response_col = f\"response_{lang}\"\n",
    "        sentence = df[response_col].apply(extract_answer)\n",
    "\n",
    "        # 위의 프롬프트 사용해서 TF 벤치마크 질문지 생성\n",
    "        wikibench_col = f\"wikibench_TF_{lang}\"\n",
    "        df[wikibench_col] = sentence.apply(make_benchmark_prompt)\n",
    "\n",
    "        # 각 모델이 TF 질문에 대한 응답한 내용 저장하는 열\n",
    "        response_TF_col = f\"response_TF_{lang}\"\n",
    "        df[response_TF_col] = \"\"\n",
    "\n",
    "        # 각 모델 응답에서 TRUE / FALSE 추출하는 열\n",
    "        extract_col = f\"extract_TF_{lang}\"\n",
    "        df[extract_col] = \"\"\n",
    "        \n",
    "        \n",
    "    BENCHMARKS.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a93e7c-8aaa-4ccf-bd4b-7c32a09b5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['row_id', 'subject', 'property', 'object', 'kind', \n",
    "             'prompt_en', 'response_en', 'wikibench_TF_en', 'response_TF_en', 'extract_TF_en', 'correct_en', \n",
    "             'prompt_fr', 'response_fr', 'wikibench_TF_fr', 'response_TF_fr', 'extract_TF_fr', 'correct_fr', \n",
    "             'prompt_de', 'response_de', 'wikibench_TF_de', 'response_TF_de', 'extract_TF_de', 'correct_de', \n",
    "             'prompt_es', 'response_es', 'wikibench_TF_es', 'response_TF_es', 'extract_TF_es', 'correct_es',\n",
    "             'prompt_it', 'response_it', 'wikibench_TF_it', 'response_TF_it', 'extract_TF_it', 'correct_it', \n",
    "             'prompt_pt', 'response_pt', 'wikibench_TF_pt', 'response_TF_pt', 'extract_TF_pt', 'correct_pt', \n",
    "             'prompt_ko', 'response_ko', 'wikibench_TF_ko', 'response_TF_ko', 'extract_TF_ko', 'correct_ko', \n",
    "             'prompt_ja', 'response_ja', 'wikibench_TF_ja', 'response_TF_ja', 'extract_TF_ja', 'correct_ja', ]\n",
    "for i in range(len(BENCHMARKS)):\n",
    "    BENCHMARKS[i] = BENCHMARKS[i][col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0306e-f8e5-45c5-9a1b-60aae25c5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_DIR = '../00.data/02.WikiBench/'\n",
    "BENCHMARK_NAME = ['00.original_benchmark_TF_500.parquet',\n",
    "                  '01.subject_shuffled_benchmark_TF_500.parquet',\n",
    "                  '02.object_shuffled_benchmark_TF_500.parquet',\n",
    "                  '03.property_scoped_subject_shuffled_benchmark_TF_500.parquet',\n",
    "                  '04.property_scoped_object_shuffled_benchmark_TF_500.parquet']\n",
    "for i in range(len(BENCHMARKS)):\n",
    "    BENCHMARKS[i].to_parquet(f\"{BENCHMARK_DIR}{BENCHMARK_NAME[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eece4ba-9c32-404b-855f-bfd95af046c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS[0].iloc[0]['wikibench_TF_ko']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caced45b-e962-4412-979a-95431424937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af859b22-afd4-4dc4-b66a-05731d1ce2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikibench",
   "language": "python",
   "name": "wikibench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
