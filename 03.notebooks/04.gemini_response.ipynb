{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a5ed79-84e6-4a70-a501-f16be864e9ab",
   "metadata": {},
   "source": [
    "| Model\t| RPM | TPM | RPD | Batch Enqueued Tokens |\n",
    "|-------|------|-----|----|--------------------|\n",
    "| Gemini 3 Pro Preview | 50 | 1,000,000 | 1,000 | 50,000,000 |\n",
    "|Gemini 2.5 Pro\t| 150\t|2,000,000\t|10,000\t|5,000,000 |\n",
    "|Gemini 2.5 Flash|1,000\t|1,000,000\t|10,000\t|3,000,000|\n",
    "|Gemini 2.5 Flash Preview|1,000\t|1,000,000|10,000|3,000,000|\n",
    "|Gemini 2.5 Flash-Lite|4,000|4,000,000\t|*\t|10,000,000|\n",
    "|Gemini 2.5 Flash-Lite Preview|4,000|4,000,000\t|*\t|10,000,000|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9f3ae-4350-404a-bb18-99688b976fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import backoff\n",
    "import threading\n",
    "import itertools\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import GenerationConfig\n",
    "import google.api_core.exceptions as gexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecb3a5-668f-4588-a367-53406e69a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_DIR = '../00.data/00.wikidata/03.wikidata_template/'\n",
    "TEMPLATE_NAME = ['00.original_template_500.parquet',\n",
    "                 '01.subject_shuffled_template_500.parquet',\n",
    "                 '02.object_shuffled_template_500.parquet',\n",
    "                 '03.property_scoped_subject_shuffled_template_500.parquet',\n",
    "                 '04.property_scoped_object_shuffled_template_500.parquet']\n",
    "\n",
    "TEMPLATE_LIST = [pq.read_table(TEMPLATE_DIR + name).to_pandas() for name in TEMPLATE_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5807d-8074-48d9-9bad-bc3494c1776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEYS = [\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05aedd-5d90-45cf-9ca3-1851d2c2cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTA = 500\n",
    "PLAN = {\n",
    "    'en': (API_KEYS[3], QUOTA),\n",
    "    'fr': (API_KEYS[4], QUOTA),\n",
    "    'de': (API_KEYS[5], QUOTA),\n",
    "    'es': (API_KEYS[6], QUOTA),\n",
    "    'it': (API_KEYS[3], QUOTA),\n",
    "    'pt': (API_KEYS[4], QUOTA),\n",
    "    'ko': (API_KEYS[5], QUOTA),\n",
    "    'ja': (API_KEYS[6], QUOTA),\n",
    "}\n",
    "LANGUAGE_LIST = ['en', 'fr', 'de', 'es', 'it', 'pt', 'ko', 'ja']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583477c-8d15-4199-a4b1-5761d9e103cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"\n",
    "CONFIG = GenerationConfig()\n",
    "MAX_WORKERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd194ff-c07f-4a88-9a09-a57509f28f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(\n",
    "    backoff.expo,\n",
    "    (gexc.ResourceExhausted, \n",
    "     gexc.InternalServerError, \n",
    "     gexc.ServiceUnavailable),\n",
    "    max_tries=6,\n",
    "    jitter=backoff.full_jitter)\n",
    "def safe_generate(model, prompt, cfg):\n",
    "    return model.generate_content(prompt, generation_config=cfg, request_options={\"timeout\": 60})\n",
    "\n",
    "class KeyLimiter:\n",
    "    def __init__(self, rpm=600):\n",
    "        self.count = 0\n",
    "        self.reset_t = time.monotonic() + 60\n",
    "        self.min_interval = 60.0 / rpm\n",
    "        self.last_call = 0.0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def wait(self):\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                now = time.monotonic()\n",
    "\n",
    "                # 분 리셋\n",
    "                if now >= self.reset_t:\n",
    "                    self.count = 0\n",
    "                    self.reset_t = now + 60\n",
    "\n",
    "                # RPM 제한\n",
    "                if self.count < 600:\n",
    "                    # burst 방지\n",
    "                    wait_time = self.min_interval - (now - self.last_call)\n",
    "                    if wait_time > 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.count += 1\n",
    "                        self.last_call = now\n",
    "                        return\n",
    "                else:\n",
    "                    wait_time = self.reset_t - now\n",
    "\n",
    "            # sleep은 lock 밖에서\n",
    "            time.sleep(max(wait_time, 0.01))\n",
    "\n",
    "LIMITER = {key: KeyLimiter() for key in API_KEYS}\n",
    "tls = threading.local()\n",
    "\n",
    "def gemini_call(task):\n",
    "    idx, lang, prompt, key = task\n",
    "\n",
    "    LIMITER[key].wait()\n",
    "\n",
    "    if not hasattr(tls, \"models\"):\n",
    "        tls.models = {}\n",
    "\n",
    "    if key not in tls.models:\n",
    "        genai.configure(api_key=key)\n",
    "        tls.models[key] = genai.GenerativeModel(MODEL_ID)\n",
    "\n",
    "    model = tls.models[key]\n",
    "    r = safe_generate(model, prompt, CONFIG)\n",
    "    return idx, lang, (r.text or \"ERROR\")\n",
    "\n",
    "def process_template(df, template_idx, output_path):\n",
    "    tasks = []\n",
    "\n",
    "    for lang, (key, quota) in PLAN.items():\n",
    "        pcol = f\"prompt_{lang}\"\n",
    "\n",
    "        for i in df.index[:quota]:\n",
    "            tasks.append((i, lang, df.at[i, pcol], key))\n",
    "\n",
    "    print(f\"[Template {template_idx}] 총 요청: {len(tasks)}\")\n",
    "\n",
    "    start = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:\n",
    "        futures = [pool.submit(gemini_call, t) for t in tasks]\n",
    "\n",
    "        for f in tqdm(as_completed(futures), total=len(tasks), desc=f\"Gemini T{template_idx}\", unit=\"req\"):\n",
    "            i, lang, txt = f.result()\n",
    "            df.at[i, f\"response_{lang}\"] = txt\n",
    "\n",
    "    print(f\"[Template {template_idx}] 완료: {time.time() - start:.1f} sec\")\n",
    "\n",
    "    pq.write_table(pa.Table.from_pandas(df), output_path)\n",
    "    print(\"[저장 완료] →\", output_path)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13272064-e91a-4b8e-a6a8-cbc1f1f89a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_BASE = \"../00.data/01.model_response/00.gemini_response/\"\n",
    "TEMPLATE_OUTPUT_NAME = [\n",
    "    \"00.original_response_500.parquet\",\n",
    "    \"01.subject_shuffled_response_500.parquet\",\n",
    "    \"02.object_shuffled_response_500.parquet\",\n",
    "    \"03.property_scoped_subject_shuffled_response_500.parquet\",\n",
    "    \"04.property_scoped_object_shuffled_response_500.parquet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea000fb-a766-4a63-9c43-9cec46bec378",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_idx, df in enumerate(TEMPLATE_LIST):\n",
    "    out_name = TEMPLATE_OUTPUT_NAME[t_idx]\n",
    "    output_file = OUTPUT_BASE + out_name\n",
    "    process_template(df.copy(), t_idx, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4758db-d680-4002-91d7-342ef29548ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = TEMPLATE_OUTPUT_NAME[2]\n",
    "output_file = OUTPUT_BASE + out_name\n",
    "process_template(TEMPLATE_LIST[2], 2, output_file)\n",
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef071e23-8750-49b2-a55f-0e0cdd2e5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = TEMPLATE_OUTPUT_NAME[3]\n",
    "output_file = OUTPUT_BASE + out_name\n",
    "process_template(TEMPLATE_LIST[3], 3, output_file)\n",
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928f143-b9b7-4581-b57a-c62dc31f15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = TEMPLATE_OUTPUT_NAME[4]\n",
    "output_file = OUTPUT_BASE + out_name\n",
    "process_template(TEMPLATE_LIST[4], 4, output_file)\n",
    "print(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506b8e2-1da5-445a-b0ab-d19076d284b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "tmp = pq.read_table('../00.data/01.model_response/00.gemini_response/04.property_scoped_object_shuffled_response_500.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d213d-4595-4ef1-9650-d3a537ec3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['prompt_en'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c4a4f-a9d3-4cd0-b672-d945dbfd57dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikibench",
   "language": "python",
   "name": "wikibench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
